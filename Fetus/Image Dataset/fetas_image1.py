# -*- coding: utf-8 -*-
"""Fetas_Image1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AY5T4i0lH4O0WVgk56NxwrFFPun3SjR5
"""

# Mount Google Drive if you are storing your dataset there
from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import cv2
import os
from glob import glob
import matplotlib.pyplot as plt

# Define the dataset paths
image_folder = '/content/drive/MyDrive/Dataset/Fetal Abdominal Structures Segmentation Dataset Using Ultrasonic Images/IMAGES'
mask_folder = '/content/drive/MyDrive/Dataset/Fetal Abdominal Structures Segmentation Dataset Using Ultrasonic Images/ARRAY_FORMAT'

# Get sorted lists of file paths for consistency
image_files = sorted(glob(os.path.join(image_folder, '*.png')))
mask_files = sorted(glob(os.path.join(mask_folder, '*.npy')))

# Verify pairing by checking the first pair
print(f"Example pair - Image: {image_files[0]}, Mask: {mask_files[0]}")

def visualize_sample(image_path, mask_path):
    # Load the image and mask data
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    mask_data = np.load(mask_path, allow_pickle=True).item()

    # Plot the original image
    plt.figure(figsize=(12, 6))
    plt.subplot(1, len(mask_data['structures']) + 1, 1)
    plt.imshow(image, cmap='gray')
    plt.title('Original Image')

    # Plot each structure mask
    for i, (name, mask) in enumerate(mask_data['structures'].items(), start=2):
        plt.subplot(1, len(mask_data['structures']) + 1, i)
        plt.imshow(mask, cmap='gray')
        plt.title(name)

    plt.show()

# Test visualization on one sample
visualize_sample(image_files[0], mask_files[0])

# Collect pairs for segmentation training
dataset = []
for img_path, mask_path in zip(image_files, mask_files):
    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    mask_data = np.load(mask_path, allow_pickle=True).item()
    dataset.append((image, mask_data['structures']))  # Store the image and its structure masks

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model

def unet_model(input_shape):
    inputs = Input(input_shape)

    # Down-sampling
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    # Down-sample more layers if needed...

    # Up-sampling
    u1 = UpSampling2D((2, 2))(p1)
    u1 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)
    u1 = concatenate([u1, c1])

    # Output layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u1)  # Adjust the number of output channels based on structure masks

    return Model(inputs=[inputs], outputs=[outputs])

# Compile the model
input_shape = (256, 256, 1)  # Adjust to your datasetâ€™s dimensions
model = unet_model(input_shape)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

from tensorflow.keras.utils import Sequence

class DataGenerator(Sequence):
    def __init__(self, dataset, batch_size=8, dim=(256, 256), n_channels=1, shuffle=True):
        self.dataset = dataset
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return len(self.dataset) // self.batch_size

    def __getitem__(self, index):
        batch_data = self.dataset[index * self.batch_size:(index + 1) * self.batch_size]
        X, y = self.__data_generation(batch_data)
        return X, y

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.dataset)

    def __data_generation(self, batch_data):
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size, *self.dim, self.n_channels))

        for i, (image, masks) in enumerate(batch_data):
            image_resized = cv2.resize(image, self.dim)
            X[i,] = np.expand_dims(image_resized, axis=-1) / 255.0  # Normalize image

            # Combine masks for segmentation
            combined_mask = np.zeros(self.dim)
            for mask in masks.values():
                mask_resized = cv2.resize(mask, self.dim)
                combined_mask = np.maximum(combined_mask, mask_resized)

            y[i,] = np.expand_dims(combined_mask, axis=-1) / 255.0  # Normalize mask

        return X, y

# Initialize generator
train_gen = DataGenerator(dataset, batch_size=8, dim=(256, 256))

# Train the model
epochs = 10
model.fit(train_gen, epochs=epochs)

# Save model after training (optional)
model.save('/content/unet_fetal_detection_model.h5')

import cv2
import numpy as np
import matplotlib.pyplot as plt

def preprocess_image(image_path, dim=(256, 256)):
    # Load and resize the image
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    image_resized = cv2.resize(image, dim)
    # Normalize and add channel dimension
    image_resized = np.expand_dims(image_resized, axis=-1) / 255.0
    # Add batch dimension
    image_resized = np.expand_dims(image_resized, axis=0)
    return image_resized

# Example usage
image_path = '/content/Patient01096_Plane2_2_of_2.png'
input_image = preprocess_image(image_path)

# Perform prediction
predicted_mask = model.predict(input_image)

# Remove batch and channel dimensions for visualization
predicted_mask = predicted_mask[0, :, :, 0]



import cv2

# Experiment with a slightly higher threshold
adjusted_threshold = 0.15
binary_mask = (normalized_mask > adjusted_threshold).astype(np.uint8)

# Apply morphological operations to clean up the mask
# Use a kernel for morphological operations
kernel = np.ones((3, 3), np.uint8)

# Apply opening (erosion followed by dilation) to remove small artifacts
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

# Apply closing (dilation followed by erosion) to close small holes
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)

# Display the refined mask
plt.figure(figsize=(12, 6))
plt.subplot(1, 3, 1)
plt.imshow(original_image_resized, cmap='gray')
plt.title('Original Image')

plt.subplot(1, 3, 2)
plt.imshow(normalized_mask, cmap='gray')
plt.title('Normalized Predicted Mask')

plt.subplot(1, 3, 3)
plt.imshow(binary_mask, cmap='gray')
plt.title(f'Refined Binary Mask (Threshold {adjusted_threshold})')

plt.show()

def get_bounding_boxes(binary_mask):
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]
    return bounding_boxes

# Extract bounding boxes from the refined binary mask
bounding_boxes = get_bounding_boxes(binary_mask)

# Draw bounding boxes on the original image
image_with_boxes = original_image_resized.copy()
for (x, y, w, h) in bounding_boxes:
    cv2.rectangle(image_with_boxes, (x, y), (x + w, y + h), (255, 0, 0), 2)

# Display the image with bounding boxes
plt.figure(figsize=(6, 6))
plt.imshow(image_with_boxes, cmap='gray')
plt.title('Detected Structures with Bounding Boxes')
plt.show()

# Check the range of the predicted mask values
print("Predicted Mask - min value:", predicted_mask.min())
print("Predicted Mask - max value:", predicted_mask.max())